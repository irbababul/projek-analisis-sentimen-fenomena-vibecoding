# ğŸ˜Š Analisis Sentimen Fenomena Vibecoding

**Aplikasi machine learning untuk menganalisis sentimen komentar YouTube terkait fenomena Vibecoding** menggunakan model **IndoBERT** yang sudah di-fine-tune dengan performa F1-macro **0.5873**.

[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)](https://github.com/RayhanLup1n/projek-analisis-sentimen-fenomena-vibecoding)
[![Branch](https://img.shields.io/badge/Branch-Dev%2FModelling-blue)](https://github.com/RayhanLup1n/projek-analisis-sentimen-fenomena-vibecoding)

---

## ğŸ¯ Tujuan Proyek

Menganalisis **sentimen publik terhadap fenomena Vibecoding** melalui:

- Scraping komentar YouTube
- Pelabelan sentiment (Positif, Netral, Negatif)
- Fine-tuning model IndoBERT
- Deployment dengan UI interaktif (Streamlit)

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Setup Environment

```bash
# Clone repository
git clone https://github.com/RayhanLup1n/projek-analisis-sentimen-fenomena-vibecoding.git
cd projek-analisis-sentimen-fenomena-vibecoding

# Create virtual environment
python -m venv venv

# Activate environment
venv\Scripts\activate          # Windows
# source venv/bin/activate     # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run Streamlit App

```bash
streamlit run app/app.py
```

Buka di browser: `http://localhost:8501`

### 3ï¸âƒ£ Train Model (Opsional)

```bash
jupyter notebook notebooks/TrainBERT.ipynb
```

---

## ğŸ“ Project Structure

```
projek-analisis-sentimen-fenomena-vibecoding/
â”‚
â”œâ”€â”€ ğŸ“‚ app/                              # â­ Streamlit application
â”‚   â””â”€â”€ app.py                           # Main UI (5 menu pages)
â”‚
â”œâ”€â”€ ğŸ“‚ models/                           # ğŸ¤– Fine-tuned models
â”‚   â”œâ”€â”€ fineTuneIndobert/                # Hyperparameter tuning results (6 configs)
â”‚   â”‚   â””â”€â”€ oversample_only_e4_lr2e-05_tar250_ml256/  â­ BEST MODEL
â”‚   â””â”€â”€ experimentsIndobert/             # Baseline experiments (4 strategies)
â”‚
â”œâ”€â”€ ğŸ“‚ data/                             # ğŸ“Š Dataset
â”‚   â”œâ”€â”€ vibe_coding_auditLabel.csv       â­ Main dataset (879 labeled comments)
â”‚   â”œâ”€â”€ vibe_coding_dataset_ready.csv
â”‚   â”œâ”€â”€ vibe_coding_yt_comments.csv
â”‚   â”œâ”€â”€ vibe_coding_yt_comments_clean.csv
â”‚   â””â”€â”€ vibe_coding_pseudoLabel.csv
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                        # ğŸ““ Jupyter notebooks
â”‚   â”œâ”€â”€ TrainBERT.ipynb                  â­ Main training (baseline + tuning)
â”‚   â””â”€â”€ eda.ipynb                        # Exploratory data analysis
â”‚
â”œâ”€â”€ ğŸ“‚ src/                              # ğŸ”§ Utility scripts
â”‚   â”œâ”€â”€ Sanitizer.py                     # Text cleaning
â”‚   â””â”€â”€ Scrape.py                        # YouTube scraper
â”‚
â”œâ”€â”€ ğŸ“‚ dev/                              # ğŸ› ï¸ Development tools
â”‚   â”œâ”€â”€ AutoLabelSentiment.py            # Auto-labeling with Groq API
â”‚   â”œâ”€â”€ GroqKeyManager.py                # API key rotation
â”‚   â””â”€â”€ [other debugging tools]
â”‚
â”œâ”€â”€ ğŸ“‚ config/                           # âš™ï¸ Configuration
â”‚   â””â”€â”€ setting.py                       # Global settings
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                             # ğŸ“– Documentation
â”‚   â”œâ”€â”€ TRAINING_GUIDE.md                # How to train models
â”‚   â”œâ”€â”€ API_KEY_ROTATION.md
â”‚   â””â”€â”€ label_sentiment_guidelines.md
â”‚
â”œâ”€â”€ ğŸ“„ README.md                         â­ This file
â”œâ”€â”€ ğŸ“„ FOLDER_TREE.txt                   # Visual tree structure
â”œâ”€â”€ ğŸ“„ requirements.txt                  # Dependencies
â””â”€â”€ [Other files & notebooks]
```

---

## ğŸ“Š Dataset Overview

| Aspek                     | Detail                                     |
| ------------------------- | ------------------------------------------ |
| **Total Comments**        | 879 komentar YouTube                       |
| **Labeling**              | Manual (audit label)                       |
| **Sentimen Distribution** | Negatif (15%), Netral (72%), Positif (13%) |
| **Train/Val Split**       | 80/20 stratified                           |
| **Preprocessing**         | Text cleaning, whitespace normalization    |

**Label Mapping**:

```python
0 = Negatif (134 samples)
1 = Netral  (630 samples)  # Majority class
2 = Positif (115 samples)
```

---

## ğŸ¤– Model Architecture

### Best Model: `oversample_only_e4_lr2e-05_tar250_ml256`

**Configuration**:

- Base Model: `indolem/indobert-base-uncased` (Indonesian BERT)
- Strategy: Oversampling minority classes (tanpa class weights)
- Epochs: 4
- Learning Rate: 2e-5
- Batch Size: 8
- Max Length: 256 tokens
- Target per class: 250 (after oversampling)

**Performance Metrics**:

| Metric          | Value         |
| --------------- | ------------- |
| **F1-macro**    | **0.5873** â­ |
| **F1-weighted** | 0.7055        |
| **Accuracy**    | 0.6875        |
| **Eval Loss**   | 0.8879        |

### Training Summary

**4 Baseline Strategies**:

1. Baseline (no oversampling, no weights)
2. Class weight only
3. Oversampling only â† **Selected for tuning**
4. Oversampling + class weights

**6 Hyperparameter Tuning Configs**:

- `e3_lr2e-05_tar250_ml256` (F1: 0.5871)
- `e4_lr2e-05_tar250_ml256` **BEST** (F1: 0.5873)
- `e3_lr3e-05_tar250_ml256` (F1: 0.5666)
- `e4_lr3e-05_tar250_ml256` (F1: 0.4529)
- `e3_lr2e-05_tar300_ml256` (F1: 0.5598)
- `e3_lr2e-05_tar250_ml128` (F1: 0.5075)

---

## ğŸ¨ Streamlit App Features

### Menu Pages:

1. **ğŸ  Beranda** (Home)

   - Deskripsi proyek
   - Informasi dataset & sentimen distribution
   - Technology stack overview

2. **ğŸ“Š Analisis Sentimen** (Sentiment Analysis)

   - Upload CSV file
   - Preview data dengan format yang benar
   - Support format: `.csv` dengan delimiter `;`

3. **ğŸ“ˆ Statistik** (Statistics)

   - Bar chart distribusi sentimen
   - Summary metrics (total, terbanyak, dll)
   - Visualisasi dengan matplotlib/plotly

4. **ğŸ” Prediksi Teks** (Text Prediction) â­ **Main Feature**

   - Input teks komentar
   - Model inference dengan caching
   - Output:
     - Predicted sentiment label
     - Confidence score (%)
     - Probability distribution (bar chart)
     - Keyword matching explanation
     - Tokenization preview
   - Model directory customizable

5. **âš™ï¸ Tentang** (About)
   - Versi aplikasi
   - Team information
   - Contact & support

### Key Features:

- ğŸ”§ **Model Caching**: Fast inference dengan `@st.cache_resource`
- ğŸ“Š **Visualizations**: Probability charts, keyword highlighting
- ğŸŒ **Bahasa**: Bilingual support (Bahasa Indonesia & English)
- ğŸ¨ **Design**: Modern UI dengan custom CSS styling
- âš¡ **Performance**: CPU/GPU compatible

---

## ğŸ”§ Technical Stack

| Komponen            | Technology                               |
| ------------------- | ---------------------------------------- |
| **ML Framework**    | PyTorch + HuggingFace Transformers       |
| **Model**           | IndoBERT (indolem/indobert-base-uncased) |
| **Training**        | HF Trainer dengan custom WeightedTrainer |
| **Data Processing** | pandas, numpy, scikit-learn, datasets    |
| **UI/Deployment**   | Streamlit                                |
| **Metrics**         | F1-macro, F1-weighted, Accuracy          |
| **Environment**     | Python 3.8+, CUDA optional               |

---

## ğŸ“– Folder Details

### `app/` - Streamlit Application

- **File**: `app.py`
- **Purpose**: Main UI untuk inferensi & visualisasi
- **Features**: 5 menu pages, model caching, responsive design

### `models/` - Trained Models

- **fineTuneIndobert/**: Hasil hyperparameter tuning (6 configs)
- **experimentsIndobert/**: Baseline strategy experiments (4 configs)
- Setiap folder berisi: `config.json`, `model.safetensors`, `tokenizer.json`, `vocab.txt`, dll

### `data/` - Dataset

- **vibe_coding_auditLabel.csv**: Main labeled dataset (â­ gunakan ini)
- **vibe_coding_dataset_ready.csv**: Preprocessed version
- **vibe_coding_yt_comments\*.csv**: Raw dan cleaned comments
- **vibe_coding_pseudoLabel.csv**: Auto-labeled dengan Groq API

### `notebooks/` - Jupyter Notebooks

- **TrainBERT.ipynb**: Complete training pipeline
  - Data loading & label mapping
  - Stratified train/val split
  - 4 baseline strategies
  - 6 hyperparameter tuning configs
  - Result comparison & best model selection
- **eda.ipynb**: Exploratory Data Analysis

### `src/` - Utility Scripts

- **Sanitizer.py**: Text cleaning (remove special chars, normalize)
- **Scrape.py**: YouTube comments scraper

### `dev/` - Development Tools

- **AutoLabelSentiment.py**: Auto-labeling dengan Groq API
- **GroqKeyManager.py**: API key rotation untuk rate limit handling
- **groqRateLimitCheck.py**: Monitor rate limit status
- Other debugging & testing utilities

### `config/` - Configuration

- **setting.py**: Global settings (PROJECT_ROOT, DATA_DIR, paths, dll)

### `docs/` - Documentation

- **TRAINING_GUIDE.md**: How to train, CLI examples, troubleshooting
- **API_KEY_ROTATION.md**: Setup API key rotation
- **label_sentiment_guidelines.md**: Sentiment labeling criteria---

## ğŸš€ How to Use

### 1. Run Streamlit App

```bash
streamlit run app/app.py
```

Then go to: `http://localhost:8501`

**Main workflow**:

1. Open **ğŸ” Prediksi Teks** menu
2. Input teks komentar (default model path will be used)
3. Click **ğŸš€ Analisis Sentimen**
4. View results: sentiment label, confidence, probability chart, keyword explanation

### 2. Upload & Analyze Dataset

```bash
# In ğŸ“Š Analisis Sentimen menu
# Upload: vibe_coding_auditLabel.csv
# Preview data, check label distribution
```

### 3. Train New Model

```bash
jupyter notebook notebooks/TrainBERT.ipynb
```

**Steps in notebook**:

1. Load data & prepare splits (80/20)
2. Run 4 baseline strategies (4 experiments)
3. Run 6 hyperparameter tuning configs
4. Compare results & select best
5. Generate classification report

---

## ğŸ“Š Data Format

**CSV Structure** (`vibe_coding_auditLabel.csv`):

```
text_raw;sentiment_pseudo;[other columns...]
"Vibecoding itu keren banget!";positif;...
"Biasa aja sih";netral;...
"Gak suka deh";negatif;...
```

**Requirements**:

- Delimiter: `;` (semicolon)
- Encoding: UTF-8
- Sentiment values: "negatif", "netral", "positif" (lowercase)

---

## ğŸ¯ Model Training Details

### Data Imbalance Solution

**Problem**: Netral class (630) >> Positif (115) & Negatif (134)

**Solution**: Oversampling minority classes to 250 samples per class

```python
Label distribution after oversampling:
- Negatif: 250 (sampled from 134)
- Netral: 630 (kept as is)
- Positif: 250 (sampled from 115)
```

### Training Process

1. **Data Loading** â†’ `vibe_coding_auditLabel.csv`
2. **Label Mapping** â†’ negatif/netral/positif â†’ 0/1/2
3. **Train/Val Split** â†’ 80/20 stratified
4. **Oversampling** â†’ Minority classes â†’ 250 samples
5. **Tokenization** â†’ Max length 256, IndoBERT tokenizer
6. **Model** â†’ IndoBERT + classification head (3 labels)
7. **Loss** â†’ CrossEntropyLoss (with optional class weights)
8. **Metrics** â†’ F1-macro, F1-weighted, Accuracy
9. **Evaluation** â†’ On validation set
10. **Save** â†’ Model + tokenizer to output directory

---

## â“ FAQ

**Q: Bagaimana cara menggunakan model yang sudah dilatih?**

A: Cukup jalankan Streamlit app:

```bash
streamlit run app/app.py
```

Lalu gunakan menu **ğŸ” Prediksi Teks** untuk input teks & dapatkan prediksi.

**Q: Model disimpan di mana?**

A: `models/fineTuneIndobert/oversample_only_e4_lr2e-05_tar250_ml256/`

- Berisi: `model.safetensors`, `tokenizer.json`, `config.json`, dll

**Q: Bisakah saya melatih dengan dataset berbeda?**

A: Ya! Edit `notebooks/TrainBERT.ipynb` cell 3 untuk mengubah `data_path` ke file CSV Anda. Pastikan format sesuai (delimiter `;`, columns: `text_raw`, `sentiment_pseudo`).

**Q: Berapa lama proses training?**

A: Tergantung hardware:

- **GPU (NVIDIA A100)**: ~45 menit per eksperimen
- **CPU**: ~2-3 jam per eksperimen
- **Total (6 configs)**: 4.5-18 jam

**Q: Kenapa F1-macro dipilih sebagai metrik utama?**

A: Karena dataset **imbalanced**. F1-macro memberikan performa rata-rata per kelas, sehingga lebih adil untuk minority classes (Positif & Negatif).

**Q: Bagaimana cara meningkatkan akurasi model?**

A: Coba:

1. Tambah data labeling (lebih banyak samples)
2. Fine-tune learning rate (1e-5, 3e-5)
3. Adjust target_per_class saat oversampling
4. Coba class weights kombinasi
5. Gunakan model BERT yang lebih besar

**Q: Aplikasi crash saat predict?**

A: Pastikan:

1. Model path benar (default: `models/fineTuneIndobert/oversample_only_e4_lr2e-05_tar250_ml256/`)
2. Dependencies installed: `pip install -r requirements.txt`
3. GPU memory cukup (atau gunakan CPU)
4. Teks input tidak kosong

---

## ğŸ”„ Model Selection Timeline

```
Initial Data (879 comments)
    â†“
Stratified Split (80/20)
    â†“
4 Baseline Strategies
â”œâ”€â”€ baseline (no oversampling, no weights)
â”œâ”€â”€ class_weight_only
â”œâ”€â”€ oversample_only â­ SELECTED
â””â”€â”€ oversample_and_weight
    â†“
6 Hyperparameter Tuning (oversample_only)
â”œâ”€â”€ e3_lr2e-05_tar250_ml256 â†’ F1: 0.5871
â”œâ”€â”€ e4_lr2e-05_tar250_ml256 â†’ F1: 0.5873 â­â­ BEST
â”œâ”€â”€ e3_lr3e-05_tar250_ml256 â†’ F1: 0.5666
â”œâ”€â”€ e4_lr3e-05_tar250_ml256 â†’ F1: 0.4529
â”œâ”€â”€ e3_lr2e-05_tar300_ml256 â†’ F1: 0.5598
â””â”€â”€ e3_lr2e-05_tar250_ml128 â†’ F1: 0.5075
    â†“
âœ… Final Model: oversample_only_e4_lr2e-05_tar250_ml256
```

---

## ğŸ¤ Contributing & Development

### Setting Up Development Environment

```bash
# Clone & setup
git clone https://github.com/RayhanLup1n/projek-analisis-sentimen-fenomena-vibecoding.git
cd projek-analisis-sentimen-fenomena-vibecoding

# Create dev branch
git checkout -b feature/your-feature

# Install dev dependencies
pip install -r requirements.txt
pip install jupyter notebook

# Make changes
# ...

# Commit & push
git add .
git commit -m "Description of changes"
git push origin feature/your-feature
```

### Code Structure

- **Training logic**: `notebooks/TrainBERT.ipynb` (primary) or `models/TrainBERT.py` (CLI)
- **App logic**: `app/app.py`
- **Config**: `config/setting.py`
- **Utilities**: `src/` (data processing), `dev/` (debugging)

---

## ğŸ“ Contact & Support

- **Repository**: https://github.com/RayhanLup1n/projek-analisis-sentimen-fenomena-vibecoding
- **Branch**: Dev/Modelling
- **Issues**: https://github.com/RayhanLup1n/projek-analisis-sentimen-fenomena-vibecoding/issues

Untuk pertanyaan, buka GitHub issue atau hubungi tim developers.

---

## ğŸ‘¥ Team

### Disusun Oleh:

1. **Rayhan Ananda Resky** (@RayhanLup1n)

   - Model architecture & training

2. **Muhammad Irbabul Salas**

   - Data scraping
   - Data Cleaning

3. **Muhammad Sawaludin**
   - Data annotation & labeling

---

## ğŸ“ License & Repository Info

**Repository**: https://github.com/RayhanLup1n/projek-analisis-sentimen-fenomena-vibecoding
**Current Branch**: Dev/Modelling
**Default Branch**: main
**License**: MIT (or specify your license)

---

## ğŸ“ References & Resources

- [IndoBERT](https://huggingface.co/indolem/indobert-base-uncased) - Indonesian BERT Model
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/) - ML Framework
- [Streamlit Documentation](https://docs.streamlit.io/) - App Framework
- [Scikit-learn Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) - Evaluation

---

**Last Updated**: November 28, 2025
**Version**: 1.0.0
**Status**: âœ… Production Ready
