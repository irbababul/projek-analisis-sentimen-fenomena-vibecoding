{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729dd963",
   "metadata": {},
   "source": [
    "# Import Library Dasar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2db86e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# Cek GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Define compute_metrics di sini agar bisa diakses di mana saja\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1_macro = f1_score(labels, preds, average='macro')\n",
    "    f1_weighted = f1_score(labels, preds, average='weighted')\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236d5b2",
   "metadata": {},
   "source": [
    "# Load Data dan Mapping Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ecd01ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>published_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_len</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>text_trunc</th>\n",
       "      <th>sentiment_pseudo</th>\n",
       "      <th>sentiment_pseudo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2wwp3dKbGE8</td>\n",
       "      <td>Ugwj1M5bLivVlqF4KkZ4AaABAg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>musfifirah7538</td>\n",
       "      <td>['bang', 'gimana', 'kalau', 'pemula', 'banget'...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-19T11:44:32Z</td>\n",
       "      <td>2025-11-19T11:44:32Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['bang', 'gimana', 'kalau', 'pemula', 'banget'...</td>\n",
       "      <td>21</td>\n",
       "      <td>bang gimana kalau pemula banget tapi mau belaj...</td>\n",
       "      <td>bang gimana kalau pemula banget tapi mau belaj...</td>\n",
       "      <td>netral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2wwp3dKbGE8</td>\n",
       "      <td>UgzZwHJ7sB8GMMgehFB4AaABAg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advhe77</td>\n",
       "      <td>['prinsip2', 'dasar', 'foundamentalnya', 'jgn'...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-18T02:28:17Z</td>\n",
       "      <td>2025-11-18T02:28:17Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['prinsip2', 'dasar', 'foundamentalnya', 'jgn'...</td>\n",
       "      <td>26</td>\n",
       "      <td>prinsip2 dasar foundamentalnya jgn smpe dilupa...</td>\n",
       "      <td>prinsip2 dasar foundamentalnya jgn smpe dilupa...</td>\n",
       "      <td>netral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2wwp3dKbGE8</td>\n",
       "      <td>UgydMEecb1Nh-PRBgq94AaABAg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zororaka</td>\n",
       "      <td>['sekedar', 'sharing', 'aja', 'pernah', 'disku...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-17T05:25:58Z</td>\n",
       "      <td>2025-11-17T05:29:49Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['sekedar', 'sharing', 'aja', 'pernah', 'disku...</td>\n",
       "      <td>45</td>\n",
       "      <td>sekedar sharing aja pernah diskusi tech lead b...</td>\n",
       "      <td>sekedar sharing aja pernah diskusi tech lead b...</td>\n",
       "      <td>netral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2wwp3dKbGE8</td>\n",
       "      <td>UgxoF9XGiQczCku-ZqJ4AaABAg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reafterstudio</td>\n",
       "      <td>['bukan', 'programer', 'tapi', 'butuh', 'websi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-14T23:31:39Z</td>\n",
       "      <td>2025-11-14T23:31:39Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['bukan', 'programer', 'tapi', 'butuh', 'websi...</td>\n",
       "      <td>70</td>\n",
       "      <td>bukan programer tapi butuh website sederhana u...</td>\n",
       "      <td>bukan programer tapi butuh website sederhana u...</td>\n",
       "      <td>positif</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2wwp3dKbGE8</td>\n",
       "      <td>UgzAbfd4HeGD1h1UxPJ4AaABAg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kurabasakurata2575</td>\n",
       "      <td>['biasa', 'ngehandle', 'pekerjaan', 'sendiri',...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-13T00:32:17Z</td>\n",
       "      <td>2025-11-13T00:32:17Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['biasa', 'ngehandle', 'pekerjaan', 'sendiri',...</td>\n",
       "      <td>51</td>\n",
       "      <td>biasa ngehandle pekerjaan sendiri punya gaya k...</td>\n",
       "      <td>biasa ngehandle pekerjaan sendiri punya gaya k...</td>\n",
       "      <td>netral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                  comment_id parent_id              author  \\\n",
       "0  2wwp3dKbGE8  Ugwj1M5bLivVlqF4KkZ4AaABAg       NaN      musfifirah7538   \n",
       "1  2wwp3dKbGE8  UgzZwHJ7sB8GMMgehFB4AaABAg       NaN             advhe77   \n",
       "2  2wwp3dKbGE8  UgydMEecb1Nh-PRBgq94AaABAg       NaN            zororaka   \n",
       "3  2wwp3dKbGE8  UgxoF9XGiQczCku-ZqJ4AaABAg       NaN       reafterstudio   \n",
       "4  2wwp3dKbGE8  UgzAbfd4HeGD1h1UxPJ4AaABAg       NaN  kurabasakurata2575   \n",
       "\n",
       "                                                text  like_count  \\\n",
       "0  ['bang', 'gimana', 'kalau', 'pemula', 'banget'...           0   \n",
       "1  ['prinsip2', 'dasar', 'foundamentalnya', 'jgn'...           0   \n",
       "2  ['sekedar', 'sharing', 'aja', 'pernah', 'disku...           0   \n",
       "3  ['bukan', 'programer', 'tapi', 'butuh', 'websi...           0   \n",
       "4  ['biasa', 'ngehandle', 'pekerjaan', 'sendiri',...           0   \n",
       "\n",
       "           published_at            updated_at  reply_count  \\\n",
       "0  2025-11-19T11:44:32Z  2025-11-19T11:44:32Z          0.0   \n",
       "1  2025-11-18T02:28:17Z  2025-11-18T02:28:17Z          0.0   \n",
       "2  2025-11-17T05:25:58Z  2025-11-17T05:29:49Z          0.0   \n",
       "3  2025-11-14T23:31:39Z  2025-11-14T23:31:39Z          0.0   \n",
       "4  2025-11-13T00:32:17Z  2025-11-13T00:32:17Z          0.0   \n",
       "\n",
       "                                              tokens  token_len  \\\n",
       "0  ['bang', 'gimana', 'kalau', 'pemula', 'banget'...         21   \n",
       "1  ['prinsip2', 'dasar', 'foundamentalnya', 'jgn'...         26   \n",
       "2  ['sekedar', 'sharing', 'aja', 'pernah', 'disku...         45   \n",
       "3  ['bukan', 'programer', 'tapi', 'butuh', 'websi...         70   \n",
       "4  ['biasa', 'ngehandle', 'pekerjaan', 'sendiri',...         51   \n",
       "\n",
       "                                            text_raw  \\\n",
       "0  bang gimana kalau pemula banget tapi mau belaj...   \n",
       "1  prinsip2 dasar foundamentalnya jgn smpe dilupa...   \n",
       "2  sekedar sharing aja pernah diskusi tech lead b...   \n",
       "3  bukan programer tapi butuh website sederhana u...   \n",
       "4  biasa ngehandle pekerjaan sendiri punya gaya k...   \n",
       "\n",
       "                                          text_trunc sentiment_pseudo  \\\n",
       "0  bang gimana kalau pemula banget tapi mau belaj...           netral   \n",
       "1  prinsip2 dasar foundamentalnya jgn smpe dilupa...           netral   \n",
       "2  sekedar sharing aja pernah diskusi tech lead b...           netral   \n",
       "3  bukan programer tapi butuh website sederhana u...          positif   \n",
       "4  biasa ngehandle pekerjaan sendiri punya gaya k...           netral   \n",
       "\n",
       "   sentiment_pseudo_id  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  2.0  \n",
       "4                  1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:/Users/Razy31/Documents/minHackathon/projek-analisis-sentimen-fenomena-vibecoding/data/vibe_coding_auditLabel.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path,sep=';', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fc32ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_pseudo\n",
       "netral     630\n",
       "negatif    134\n",
       "positif    115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_pseudo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d453e9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    134\n",
       "1    630\n",
       "2    115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pastikan kolom yang diperlukan sudah ada\n",
    "assert 'text_raw' in df.columns\n",
    "assert 'sentiment_pseudo' in df.columns\n",
    "\n",
    "df['text_raw'] = (\n",
    "    df['text_raw'].astype(str).fillna(\"\").\n",
    "    str.replace('\\n', ' ',regex=False).\n",
    "    str.strip()\n",
    ")\n",
    "\n",
    "label_map = {\n",
    "    \"negatif\": 0,\n",
    "    \"netral\": 1,\n",
    "    \"positif\": 2\n",
    "}\n",
    "\n",
    "df['label'] = df['sentiment_pseudo'].str.lower().map(label_map)\n",
    "df['label'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83bd54",
   "metadata": {},
   "source": [
    "# Helper: Split, Oversampling, Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b22f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label dist: {0: 107, 1: 504, 2: 92}\n",
      "Val label dist: {0: 27, 1: 126, 2: 23}\n"
     ]
    }
   ],
   "source": [
    "# Stratified split train dan val\n",
    "def make_splits(df, test_size=0.2, seed=42):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df['text_raw'].tolist(),\n",
    "        df['label'].tolist(),\n",
    "        test_size=test_size,\n",
    "        random_state=seed,\n",
    "        stratify=df['label'].tolist(),\n",
    "    )\n",
    "    train_df = pd.DataFrame({'text_raw': X_train, 'label': y_train})\n",
    "    val_df = pd.DataFrame({'text_raw': X_val, 'label': y_val})\n",
    "    return train_df, val_df\n",
    "\n",
    "train_df_base, val_df_base = make_splits(df)\n",
    "print(\"Train label dist:\",train_df_base['label'].value_counts().sort_index().to_dict())\n",
    "print(\"Val label dist:\",val_df_base['label'].value_counts().sort_index().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "918da350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling minoritas di train set\n",
    "def oversampling_minority(df, label_col='label', target='label', target_per_class=250, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dfs = []\n",
    "    \n",
    "    for lbl, group in df.groupby(label_col):\n",
    "        if len(group) >= target_per_class:\n",
    "            dfs.append(group)\n",
    "        else:\n",
    "            needed = target_per_class - len(group)\n",
    "            extra_idx = rng.choice(group.index, size=needed, replace=True)\n",
    "            extra_samples = group.loc[extra_idx]\n",
    "            dfs.append(pd.concat([group, extra_samples], axis=0))\n",
    "    df_os = pd.concat(dfs, axis=0).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    return df_os\n",
    "\n",
    "\n",
    "# Tokenization Helper\n",
    "model_name = 'indolem/indobert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch['text_raw'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=256,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c310e",
   "metadata": {},
   "source": [
    "# WeightTrainer & Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd3e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    Trainer HF + CrossEntropyLoss dengan class weights\n",
    "    \"\"\"\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            cw = self.class_weights.to(logits.device)\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=cw)\n",
    "            \n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "        \n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601c308",
   "metadata": {},
   "source": [
    "# Buat `run_experiment` untuk 1 strategi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81056c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    strategy_name: str,\n",
    "    base_train_df: pd.DataFrame,\n",
    "    base_val_df: pd.DataFrame,\n",
    "    oversample: bool,\n",
    "    use_class_weight: bool,\n",
    "    epochs: int = 5,\n",
    "    batch_size: int = 8,\n",
    "    lr: float=2e-5,\n",
    "    target_per_class: int = 250,\n",
    "    output_root: str = \"../models/experimentsIndobert\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Jalankan satu eksperimen:\n",
    "    - oversampling train (opsional)\n",
    "    - class_weights (opsional)\n",
    "    - fine-tune IndoBERT\n",
    "    - evaluate di val\n",
    "    \"\"\"\n",
    "    print(f\"\\n===== Experiment: {strategy_name} =====\")\n",
    "    \n",
    "    # 1) siapkan train_df sesuai strategi\n",
    "    if oversample:\n",
    "        train_df = oversampling_minority(\n",
    "            base_train_df, target_per_class=target_per_class)\n",
    "        print(\"Train label dist (oversampled):\", train_df['label'].value_counts().sort_index().to_dict())\n",
    "    else:\n",
    "        train_df = base_train_df.copy()\n",
    "        print(\"Train Label dist (base):\", train_df['label'].value_counts().sort_index().to_dict())\n",
    "        \n",
    "        \n",
    "    val_df = base_val_df.copy()\n",
    "    print(\"Val label dist:\", val_df['label'].value_counts().sort_index().to_dict())\n",
    "    \n",
    "    # 2) Hitung class_weights kalau dipakai\n",
    "    class_weights_tensor = None\n",
    "    if use_class_weight:\n",
    "        label_counts = train_df['label'].value_counts().sort_index()\n",
    "        counts = label_counts.values.astype(float)\n",
    "        inv_freq = 1.0 / counts\n",
    "        class_weights = inv_freq / inv_freq.sum() * len(counts)\n",
    "        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "        print(\"Class Weights (0,1,2):\", class_weights_tensor.tolist())\n",
    "    else:\n",
    "        print(\"Class Weigths: Not Used\")\n",
    "        \n",
    "    # 3) Siapkan dataset HF\n",
    "    train_dfs = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "    val_dfs = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "    \n",
    "    train_dfs = train_dfs.map(tokenize_function, batched=True)\n",
    "    val_dfs = val_dfs.map(tokenize_function, batched=True)\n",
    "    \n",
    "    train_dfs = train_dfs.remove_columns(['text_raw'])\n",
    "    val_dfs = val_dfs.remove_columns(['text_raw'])\n",
    "    \n",
    "    train_dfs = train_dfs.with_format(\"torch\")\n",
    "    val_dfs = val_dfs.with_format(\"torch\")\n",
    "    \n",
    "    # 4) Load model baru tiap eksperimen (biar fair)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=3,\n",
    "    ).to(device)\n",
    "    \n",
    "    # 5) TrainingArguments minimal\n",
    "    exp_output_dir = os.path.join(output_root, strategy_name)\n",
    "    os.makedirs(exp_output_dir, exist_ok=True)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=exp_output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=lr,\n",
    "        logging_steps=50,\n",
    "        save_total_limit=1,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "    \n",
    "    trainer = WeightedTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dfs,\n",
    "        eval_dataset=val_dfs,\n",
    "        compute_metrics=compute_metrics,\n",
    "        class_weights=class_weights_tensor,\n",
    "    )\n",
    "    \n",
    "    # 6) Train\n",
    "    train_result = trainer.train()\n",
    "    print(\"Train result:\", train_result.metrics)\n",
    "    \n",
    "    # 7) Evaluate\n",
    "    eval_result = trainer.evaluate()\n",
    "    print(\"Eval result:\", eval_result)\n",
    "    \n",
    "    \n",
    "    # 8) Prediksi detail untuk classfication report\n",
    "    pred_output = trainer.predict(val_dfs)\n",
    "    y_true = pred_output.label_ids\n",
    "    y_pred = np.argmax(pred_output.predictions, axis=1)\n",
    "    \n",
    "    cls_report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=['negatif', 'netral', 'positif'],\n",
    "        digits=3,\n",
    "        output_dict=True, #disimpan dalam bentuk dictionary\n",
    "    )\n",
    "    \n",
    "    # 9) save model & tokenizer (optional: hanya yang terbaik nanti)\n",
    "    trainer.save_model(exp_output_dir)\n",
    "    tokenizer.save_pretrained(exp_output_dir)\n",
    "    \n",
    "    return{\n",
    "                \"name\": strategy_name,\n",
    "        \"oversample\": oversample,\n",
    "        \"use_class_weight\": use_class_weight,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": lr,\n",
    "        \"target_per_class\": target_per_class,\n",
    "        \"eval_metrics\": eval_result,\n",
    "        \"cls_report\": cls_report,\n",
    "        \"output_dir\": exp_output_dir,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5195b27a",
   "metadata": {},
   "source": [
    "# Looping semua strategi & ringkasan hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d683fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Experiment: baseline =====\n",
      "Train Label dist (base): {0: 107, 1: 504, 2: 92}\n",
      "Val label dist: {0: 27, 1: 126, 2: 23}\n",
      "Class Weigths: Not Used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242bafc2a79542a1bc055a6bc91869ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce153974700441f68f80b062ec3f66c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [264/264 39:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.808700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.518100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train result: {'train_runtime': 2360.645, 'train_samples_per_second': 0.893, 'train_steps_per_second': 0.112, 'total_flos': 277453098994176.0, 'train_loss': 0.6621764862176144, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'eval_loss': 0.7889192700386047, 'eval_accuracy': 0.6931818181818182, 'eval_f1_macro': 0.407843137254902, 'eval_f1_weighted': 0.6418449197860963, 'eval_runtime': 46.6246, 'eval_samples_per_second': 3.775, 'eval_steps_per_second': 0.472, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Experiment: class_weight_only =====\n",
      "Train Label dist (base): {0: 107, 1: 504, 2: 92}\n",
      "Val label dist: {0: 27, 1: 126, 2: 23}\n",
      "Class Weights (0,1,2): [1.2629743814468384, 0.26813146471977234, 1.468894124031067]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef0c597a59840598908a44d1db1b6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4ec16766394e5a8e15cfa43f441be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [264/264 28:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.978300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.959100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.807400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train result: {'train_runtime': 1739.0668, 'train_samples_per_second': 1.213, 'train_steps_per_second': 0.152, 'total_flos': 277453098994176.0, 'train_loss': 0.9450688470493663, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'eval_loss': 0.9001913070678711, 'eval_accuracy': 0.6136363636363636, 'eval_f1_macro': 0.5223657434981139, 'eval_f1_weighted': 0.6401669196243254, 'eval_runtime': 33.3046, 'eval_samples_per_second': 5.285, 'eval_steps_per_second': 0.661, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Experiment: oversample_only =====\n",
      "Train label dist (oversampled): {0: 250, 1: 504, 2: 250}\n",
      "Val label dist: {0: 27, 1: 126, 2: 23}\n",
      "Class Weigths: Not Used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73849f153204891a704e503b84c276a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b320dfa5e8b41918e7fbef227efe07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [378/378 41:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.852700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.811200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.694900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.479900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train result: {'train_runtime': 2515.4715, 'train_samples_per_second': 1.197, 'train_steps_per_second': 0.15, 'total_flos': 396248807098368.0, 'train_loss': 0.6784836274606211, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'eval_loss': 0.6938790678977966, 'eval_accuracy': 0.6761363636363636, 'eval_f1_macro': 0.563903494536406, 'eval_f1_weighted': 0.6929990262901655, 'eval_runtime': 32.7647, 'eval_samples_per_second': 5.372, 'eval_steps_per_second': 0.671, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Experiment: oversample_and_weight =====\n",
      "Train label dist (oversampled): {0: 250, 1: 504, 2: 250}\n",
      "Val label dist: {0: 27, 1: 126, 2: 23}\n",
      "Class Weights (0,1,2): [1.201907753944397, 0.5961844325065613, 1.201907753944397]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b1225009864887b193b5ab59fb7247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee27ef09c5dd4e88bcbcd74ca719cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [378/378 41:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.953500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.926300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.818600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.570500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.554100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train result: {'train_runtime': 2469.7946, 'train_samples_per_second': 1.22, 'train_steps_per_second': 0.153, 'total_flos': 396248807098368.0, 'train_loss': 0.776834593878852, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'eval_loss': 0.9110493063926697, 'eval_accuracy': 0.5909090909090909, 'eval_f1_macro': 0.5163015708187048, 'eval_f1_weighted': 0.6262060131803122, 'eval_runtime': 33.7217, 'eval_samples_per_second': 5.219, 'eval_steps_per_second': 0.652, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "strategies = [\n",
    "    {\"name\": \"baseline\",              \"oversample\": False, \"use_class_weight\": False},\n",
    "    {\"name\": \"class_weight_only\",     \"oversample\": False, \"use_class_weight\": True},\n",
    "    {\"name\": \"oversample_only\",       \"oversample\": True,  \"use_class_weight\": False},\n",
    "    {\"name\": \"oversample_and_weight\", \"oversample\": True,  \"use_class_weight\": True},\n",
    "]\n",
    "\n",
    "experiments = []\n",
    "for cfg in strategies:\n",
    "    result = run_experiment(\n",
    "        strategy_name=cfg[\"name\"],\n",
    "        base_train_df=train_df_base,\n",
    "        base_val_df=val_df_base,\n",
    "        oversample=cfg[\"oversample\"],\n",
    "        use_class_weight=cfg[\"use_class_weight\"],\n",
    "        epochs=3,           # bisa kamu ubah global di sini\n",
    "        batch_size=8,\n",
    "        lr=2e-5,\n",
    "        target_per_class=250,\n",
    "        output_root=\"models/experiments_indobert\",\n",
    "    )\n",
    "    experiments.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a4b227",
   "metadata": {},
   "source": [
    "# Table Perbandingan & pilih yang terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b06d6bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>oversample</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>output_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oversample_only</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.693879</td>\n",
       "      <td>0.676136</td>\n",
       "      <td>0.563903</td>\n",
       "      <td>0.692999</td>\n",
       "      <td>models/experiments_indobert\\oversample_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class_weight_only</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.900191</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.522366</td>\n",
       "      <td>0.640167</td>\n",
       "      <td>models/experiments_indobert\\class_weight_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oversample_and_weight</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.911049</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.516302</td>\n",
       "      <td>0.626206</td>\n",
       "      <td>models/experiments_indobert\\oversample_and_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.788919</td>\n",
       "      <td>0.693182</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.641845</td>\n",
       "      <td>models/experiments_indobert\\baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  oversample  class_weight  epochs  batch_size  \\\n",
       "2        oversample_only        True         False       3           8   \n",
       "1      class_weight_only       False          True       3           8   \n",
       "3  oversample_and_weight        True          True       3           8   \n",
       "0               baseline       False         False       3           8   \n",
       "\n",
       "        lr  eval_loss  accuracy  f1_macro  f1_weighted  \\\n",
       "2  0.00002   0.693879  0.676136  0.563903     0.692999   \n",
       "1  0.00002   0.900191  0.613636  0.522366     0.640167   \n",
       "3  0.00002   0.911049  0.590909  0.516302     0.626206   \n",
       "0  0.00002   0.788919  0.693182  0.407843     0.641845   \n",
       "\n",
       "                                          output_dir  \n",
       "2        models/experiments_indobert\\oversample_only  \n",
       "1      models/experiments_indobert\\class_weight_only  \n",
       "3  models/experiments_indobert\\oversample_and_weight  \n",
       "0               models/experiments_indobert\\baseline  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for exp in experiments:\n",
    "    m = exp[\"eval_metrics\"]\n",
    "    rows.append({\n",
    "        \"name\": exp[\"name\"],\n",
    "        \"oversample\": exp[\"oversample\"],\n",
    "        \"class_weight\": exp[\"use_class_weight\"],\n",
    "        \"epochs\": exp[\"epochs\"],\n",
    "        \"batch_size\": exp[\"batch_size\"],\n",
    "        \"lr\": exp[\"lr\"],\n",
    "        \"eval_loss\": m.get(\"eval_loss\", None),\n",
    "        \"accuracy\": m.get(\"eval_accuracy\", None),\n",
    "        \"f1_macro\": m.get(\"eval_f1_macro\", None),\n",
    "        \"f1_weighted\": m.get(\"eval_f1_weighted\", None),\n",
    "        \"output_dir\": exp[\"output_dir\"],\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values(by=\"f1_macro\", ascending=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ad5e9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('oversample_only',\n",
       " {'eval_loss': 0.6938790678977966,\n",
       "  'eval_accuracy': 0.6761363636363636,\n",
       "  'eval_f1_macro': 0.563903494536406,\n",
       "  'eval_f1_weighted': 0.6929990262901655,\n",
       "  'eval_runtime': 32.7647,\n",
       "  'eval_samples_per_second': 5.372,\n",
       "  'eval_steps_per_second': 0.671,\n",
       "  'epoch': 3.0},\n",
       " 'models/experiments_indobert\\\\oversample_only')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pilih eksperimen terbaik berdasarkan f1_macro\n",
    "best_exp = max(experiments, key=lambda e: e[\"eval_metrics\"].get(\"eval_f1_macro\", 0))\n",
    "best_exp[\"name\"], best_exp[\"eval_metrics\"], best_exp[\"output_dir\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3621387f",
   "metadata": {},
   "source": [
    "# Fine Tune untuk `oversample_only`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a18d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokenize_fn(max_length):\n",
    "    def tokenize_batch(batch):\n",
    "        return tokenizer(\n",
    "            batch['text_raw'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_length,\n",
    "        )\n",
    "    return tokenize_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "451f4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    strategy_name: str,\n",
    "    base_train_df: pd.DataFrame,\n",
    "    base_val_df: pd.DataFrame,\n",
    "    epochs: int =3,\n",
    "    batch_size: int=8,\n",
    "    lr: float=2e-5,\n",
    "    target_per_class: int =250,\n",
    "    max_length: int =256,\n",
    "    output_root: str =\"../models/fineTuneIndobert\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Satu ekperimen dengan:\n",
    "    - Oversampling minor class (selalu True disini)\n",
    "    - tanpa class_weight (oversample_only)\n",
    "    - Hyperparam bisa di-set: epochs, batch_size, lr, target_per_class, max_length\n",
    "    \"\"\"\n",
    "    print(f\"\\n===== EXP: {strategy_name} =====\")\n",
    "    print(f\"epochs={epochs}, lr={lr}, target_per_class={target_per_class}, max_len={max_length}, batch={batch_size}\")\n",
    "\n",
    "    # 1) Oversample train\n",
    "    train_df = oversampling_minority(base_train_df, target_per_class=target_per_class)\n",
    "    val_df   = base_val_df.copy()\n",
    "\n",
    "    print(\"Train label dist (oversampled):\", train_df[\"label\"].value_counts().sort_index().to_dict())\n",
    "    print(\"Val   label dist:\", val_df[\"label\"].value_counts().sort_index().to_dict())\n",
    "\n",
    "    # 2) Dataset HF + tokenization sesuai max_length\n",
    "    tok_fn = make_tokenize_fn(max_length=max_length)\n",
    "\n",
    "    train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "    val_ds   = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "    train_ds = train_ds.map(tok_fn, batched=True)\n",
    "    val_ds   = val_ds.map(tok_fn, batched=True)\n",
    "\n",
    "    train_ds = train_ds.remove_columns([\"text_raw\"])\n",
    "    val_ds   = val_ds.remove_columns([\"text_raw\"])\n",
    "\n",
    "    train_ds = train_ds.with_format(\"torch\")\n",
    "    val_ds   = val_ds.with_format(\"torch\")\n",
    "\n",
    "    # 3) Model fresh\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=3,\n",
    "    ).to(device)\n",
    "\n",
    "    # 4) TrainingArguments minimal\n",
    "    exp_output_dir = os.path.join(output_root, strategy_name)\n",
    "    os.makedirs(exp_output_dir, exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=exp_output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=lr,\n",
    "        logging_steps=50,\n",
    "        save_total_limit=1,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "        class_weights=None,  # oversample_only => TANPA class_weight\n",
    "    )\n",
    "\n",
    "    # 5) Train + eval\n",
    "    train_result = trainer.train()\n",
    "    print(\"Train metrics:\", train_result.metrics)\n",
    "\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    print(\"Eval metrics:\", eval_metrics)\n",
    "\n",
    "    # 6) Classification report (biar bisa dicek detail kalau perlu)\n",
    "    pred_output = trainer.predict(val_ds)\n",
    "    y_true = pred_output.label_ids\n",
    "    y_pred = np.argmax(pred_output.predictions, axis=1)\n",
    "\n",
    "    cls_report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=[\"negatif\", \"netral\", \"positif\"],\n",
    "        digits=3,\n",
    "        output_dict=True,\n",
    "    )\n",
    "\n",
    "    # 7) Save model & tokenizer\n",
    "    trainer.save_model(exp_output_dir)\n",
    "    tokenizer.save_pretrained(exp_output_dir)\n",
    "\n",
    "    return {\n",
    "        \"name\": strategy_name,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": lr,\n",
    "        \"target_per_class\": target_per_class,\n",
    "        \"max_length\": max_length,\n",
    "        \"eval_metrics\": eval_metrics,\n",
    "        \"cls_report\": cls_report,\n",
    "        \"output_dir\": exp_output_dir,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9007d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EXP: oversample_only_e3_lr2e-05_tar250_ml256 =====\n",
      "epochs=3, lr=2e-05, target_per_class=250, max_len=256, batch=8\n",
      "Train label dist (oversampled): {0: 250, 1: 504, 2: 250}\n",
      "Val   label dist: {0: 27, 1: 126, 2: 23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9808a83c9605452b954ef7d4f9b16c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b807a12f9a3c40ad9d3ce90039b2f565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [378/378 41:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.841800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.528100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.382500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.403600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'train_runtime': 2501.1648, 'train_samples_per_second': 1.204, 'train_steps_per_second': 0.151, 'total_flos': 396248807098368.0, 'train_loss': 0.6225620930787747, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.7761140465736389, 'eval_accuracy': 0.6704545454545454, 'eval_f1_macro': 0.587141874293577, 'eval_f1_weighted': 0.6906305285272003, 'eval_runtime': 32.6132, 'eval_samples_per_second': 5.397, 'eval_steps_per_second': 0.675, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EXP: oversample_only_e4_lr2e-05_tar250_ml256 =====\n",
      "epochs=4, lr=2e-05, target_per_class=250, max_len=256, batch=8\n",
      "Train label dist (oversampled): {0: 250, 1: 504, 2: 250}\n",
      "Val   label dist: {0: 27, 1: 126, 2: 23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53439137afb64075b76d8c2c5a7fc5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c502e188c4b47369a66d7546726f481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [504/504 55:49, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.837400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.820500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.640400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.405900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.245600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.218200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'train_runtime': 3356.3476, 'train_samples_per_second': 1.197, 'train_steps_per_second': 0.15, 'total_flos': 528331742797824.0, 'train_loss': 0.5340192800476438, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.8879430294036865, 'eval_accuracy': 0.6875, 'eval_f1_macro': 0.5872758535986243, 'eval_f1_weighted': 0.7055277349768875, 'eval_runtime': 32.0165, 'eval_samples_per_second': 5.497, 'eval_steps_per_second': 0.687, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EXP: oversample_only_e3_lr3e-05_tar250_ml256 =====\n",
      "epochs=3, lr=3e-05, target_per_class=250, max_len=256, batch=8\n",
      "Train label dist (oversampled): {0: 250, 1: 504, 2: 250}\n",
      "Val   label dist: {0: 27, 1: 126, 2: 23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c917db5fb634011950298fa5baba463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c4f6dc2cb44572899df8825a2e92d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [378/378 40:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.885400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.615200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.462600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'train_runtime': 2431.1471, 'train_samples_per_second': 1.239, 'train_steps_per_second': 0.155, 'total_flos': 396248807098368.0, 'train_loss': 0.6674688959878589, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.8034815192222595, 'eval_accuracy': 0.6647727272727273, 'eval_f1_macro': 0.566556319497496, 'eval_f1_weighted': 0.6865786397203509, 'eval_runtime': 31.6012, 'eval_samples_per_second': 5.569, 'eval_steps_per_second': 0.696, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EXP: oversample_only_e4_lr3e-05_tar250_ml256 =====\n",
      "epochs=4, lr=3e-05, target_per_class=250, max_len=256, batch=8\n",
      "Train label dist (oversampled): {0: 250, 1: 504, 2: 250}\n",
      "Val   label dist: {0: 27, 1: 126, 2: 23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c4e9eccce14c8fa74a160fc1aa0dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c858f89dbba4607bf076ed52db64d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [504/504 1:03:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.872300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.804800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.649700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.613600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.675400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'train_runtime': 3791.8725, 'train_samples_per_second': 1.059, 'train_steps_per_second': 0.133, 'total_flos': 528331742797824.0, 'train_loss': 0.8032643208428035, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 1.004328966140747, 'eval_accuracy': 0.6193181818181818, 'eval_f1_macro': 0.4529001970790969, 'eval_f1_weighted': 0.6314760075043033, 'eval_runtime': 44.0918, 'eval_samples_per_second': 3.992, 'eval_steps_per_second': 0.499, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EXP: oversample_only_e3_lr2e-05_tar300_ml256 =====\n",
      "epochs=3, lr=2e-05, target_per_class=300, max_len=256, batch=8\n",
      "Train label dist (oversampled): {0: 300, 1: 504, 2: 300}\n",
      "Val   label dist: {0: 27, 1: 126, 2: 23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c112e85112ed4118a57960b00dbb1827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a5a31b1553415c95ee857104e10c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='414' max='414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [414/414 56:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.874700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.916600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.771900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.678700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.448100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.453800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'train_runtime': 3367.7435, 'train_samples_per_second': 0.983, 'train_steps_per_second': 0.123, 'total_flos': 435715819757568.0, 'train_loss': 0.7114589387092037, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.7708637714385986, 'eval_accuracy': 0.6363636363636364, 'eval_f1_macro': 0.5598212485051967, 'eval_f1_weighted': 0.6619687484748552, 'eval_runtime': 33.1371, 'eval_samples_per_second': 5.311, 'eval_steps_per_second': 0.664, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EXP: oversample_only_e3_lr2e-05_tar250_ml128 =====\n",
      "epochs=3, lr=2e-05, target_per_class=250, max_len=128, batch=8\n",
      "Train label dist (oversampled): {0: 250, 1: 504, 2: 250}\n",
      "Val   label dist: {0: 27, 1: 126, 2: 23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08bf1b63c0c4596a81d95da78b38eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d90345de87a4ff09d82ebc8a0ce26dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [378/378 19:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.888600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.843800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.747600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.539000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'train_runtime': 1172.228, 'train_samples_per_second': 2.569, 'train_steps_per_second': 0.322, 'total_flos': 198124403549184.0, 'train_loss': 0.7245212131076388, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.8796199560165405, 'eval_accuracy': 0.6136363636363636, 'eval_f1_macro': 0.5074818955415971, 'eval_f1_weighted': 0.6433426060291733, 'eval_runtime': 20.6736, 'eval_samples_per_second': 8.513, 'eval_steps_per_second': 1.064, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Razy31\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>target_per_class</th>\n",
       "      <th>max_length</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>output_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oversample_only_e4_lr2e-05_tar250_ml256</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>250</td>\n",
       "      <td>256</td>\n",
       "      <td>0.887943</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.587276</td>\n",
       "      <td>0.705528</td>\n",
       "      <td>../models/fineTuneIndobert\\oversample_only_e4_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oversample_only_e3_lr2e-05_tar250_ml256</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>250</td>\n",
       "      <td>256</td>\n",
       "      <td>0.776114</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.587142</td>\n",
       "      <td>0.690631</td>\n",
       "      <td>../models/fineTuneIndobert\\oversample_only_e3_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oversample_only_e3_lr3e-05_tar250_ml256</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>250</td>\n",
       "      <td>256</td>\n",
       "      <td>0.803482</td>\n",
       "      <td>0.664773</td>\n",
       "      <td>0.566556</td>\n",
       "      <td>0.686579</td>\n",
       "      <td>../models/fineTuneIndobert\\oversample_only_e3_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oversample_only_e3_lr2e-05_tar300_ml256</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>0.770864</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.559821</td>\n",
       "      <td>0.661969</td>\n",
       "      <td>../models/fineTuneIndobert\\oversample_only_e3_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oversample_only_e3_lr2e-05_tar250_ml128</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>250</td>\n",
       "      <td>128</td>\n",
       "      <td>0.879620</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.507482</td>\n",
       "      <td>0.643343</td>\n",
       "      <td>../models/fineTuneIndobert\\oversample_only_e3_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oversample_only_e4_lr3e-05_tar250_ml256</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>250</td>\n",
       "      <td>256</td>\n",
       "      <td>1.004329</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.452900</td>\n",
       "      <td>0.631476</td>\n",
       "      <td>../models/fineTuneIndobert\\oversample_only_e4_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  epochs  batch_size       lr  \\\n",
       "1  oversample_only_e4_lr2e-05_tar250_ml256       4           8  0.00002   \n",
       "0  oversample_only_e3_lr2e-05_tar250_ml256       3           8  0.00002   \n",
       "2  oversample_only_e3_lr3e-05_tar250_ml256       3           8  0.00003   \n",
       "4  oversample_only_e3_lr2e-05_tar300_ml256       3           8  0.00002   \n",
       "5  oversample_only_e3_lr2e-05_tar250_ml128       3           8  0.00002   \n",
       "3  oversample_only_e4_lr3e-05_tar250_ml256       4           8  0.00003   \n",
       "\n",
       "   target_per_class  max_length  eval_loss  accuracy  f1_macro  f1_weighted  \\\n",
       "1               250         256   0.887943  0.687500  0.587276     0.705528   \n",
       "0               250         256   0.776114  0.670455  0.587142     0.690631   \n",
       "2               250         256   0.803482  0.664773  0.566556     0.686579   \n",
       "4               300         256   0.770864  0.636364  0.559821     0.661969   \n",
       "5               250         128   0.879620  0.613636  0.507482     0.643343   \n",
       "3               250         256   1.004329  0.619318  0.452900     0.631476   \n",
       "\n",
       "                                          output_dir  \n",
       "1  ../models/fineTuneIndobert\\oversample_only_e4_...  \n",
       "0  ../models/fineTuneIndobert\\oversample_only_e3_...  \n",
       "2  ../models/fineTuneIndobert\\oversample_only_e3_...  \n",
       "4  ../models/fineTuneIndobert\\oversample_only_e3_...  \n",
       "5  ../models/fineTuneIndobert\\oversample_only_e3_...  \n",
       "3  ../models/fineTuneIndobert\\oversample_only_e4_...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_configs = [\n",
    "    {\"epochs\": 3, \"lr\": 2e-5, \"target_per_class\": 250, \"max_length\": 256},\n",
    "    {\"epochs\": 4, \"lr\": 2e-5, \"target_per_class\": 250, \"max_length\": 256},\n",
    "    {\"epochs\": 3, \"lr\": 3e-5, \"target_per_class\": 250, \"max_length\": 256},\n",
    "    {\"epochs\": 4, \"lr\": 3e-5, \"target_per_class\": 250, \"max_length\": 256},\n",
    "    {\"epochs\": 3, \"lr\": 2e-5, \"target_per_class\": 300, \"max_length\": 256},\n",
    "    {\"epochs\": 3, \"lr\": 2e-5, \"target_per_class\": 250, \"max_length\": 128},\n",
    "]\n",
    "\n",
    "experiments_tuned = []\n",
    "\n",
    "for i, cfg in enumerate(search_configs):\n",
    "    name = f\"oversample_only_e{cfg['epochs']}_lr{cfg['lr']}_tar{cfg['target_per_class']}_ml{cfg['max_length']}\"\n",
    "    result = run_experiment(\n",
    "        strategy_name=name,\n",
    "        base_train_df=train_df_base,\n",
    "        base_val_df=val_df_base,\n",
    "        epochs=cfg[\"epochs\"],\n",
    "        batch_size=8,\n",
    "        lr=cfg[\"lr\"],\n",
    "        target_per_class=cfg[\"target_per_class\"],\n",
    "        max_length=cfg[\"max_length\"],\n",
    "        output_root=\"../models/fineTuneIndobert\",\n",
    "    )\n",
    "    experiments_tuned.append(result)\n",
    "\n",
    "rows = []\n",
    "for exp in experiments_tuned:\n",
    "    m = exp[\"eval_metrics\"]\n",
    "    rows.append({\n",
    "        \"name\": exp[\"name\"],\n",
    "        \"epochs\": exp[\"epochs\"],\n",
    "        \"batch_size\": exp[\"batch_size\"],\n",
    "        \"lr\": exp[\"lr\"],\n",
    "        \"target_per_class\": exp[\"target_per_class\"],\n",
    "        \"max_length\": exp[\"max_length\"],\n",
    "        \"eval_loss\": m.get(\"eval_loss\", None),\n",
    "        \"accuracy\": m.get(\"eval_accuracy\", None),\n",
    "        \"f1_macro\": m.get(\"eval_f1_macro\", None),\n",
    "        \"f1_weighted\": m.get(\"eval_f1_weighted\", None),\n",
    "        \"output_dir\": exp[\"output_dir\"],\n",
    "    })\n",
    "\n",
    "tuned_summary_df = pd.DataFrame(rows).sort_values(by=\"f1_macro\", ascending=False)\n",
    "tuned_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37b0fa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('oversample_only_e4_lr2e-05_tar250_ml256',\n",
       " {'eval_loss': 0.8879430294036865,\n",
       "  'eval_accuracy': 0.6875,\n",
       "  'eval_f1_macro': 0.5872758535986243,\n",
       "  'eval_f1_weighted': 0.7055277349768875,\n",
       "  'eval_runtime': 32.0165,\n",
       "  'eval_samples_per_second': 5.497,\n",
       "  'eval_steps_per_second': 0.687,\n",
       "  'epoch': 4.0},\n",
       " '../models/fineTuneIndobert\\\\oversample_only_e4_lr2e-05_tar250_ml256')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tuned = max(experiments_tuned, key=lambda e: e[\"eval_metrics\"].get(\"eval_f1_macro\", 0))\n",
    "best_tuned[\"name\"], best_tuned[\"eval_metrics\"], best_tuned[\"output_dir\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
